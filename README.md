# ğŸ¥ Diabetes Hospital Stay Prediction  

*A Machine Learning Pipeline for Predicting Inpatient Length of Stay among Diabetic Patients*

---

<p align="center">
  <img src="assets/images/pipeline_diagram.png" alt="Pipeline Overview" width="850"/>
</p>

> **Figure:** End-to-end pipeline from UCI Diabetes Dataset â†’ Preprocessing (EDA) â†’ Feature Engineering â†’ Model Training â†’ Explainability.

---

### ğŸ“˜ **Project Overview**

This repository presents a complete **end-to-end regression pipeline** built to predict the  
**length of hospital stay (`time_in_hospital`)** for diabetic patients using data from  
**130 US hospitals (1999â€“2008)** â€” sourced from the **UCI Machine Learning Repository**.

The workflow covers every stage of a modern ML lifecycle:

1. **Data Exploration & Cleaning** â€” handling missing, inconsistent, and categorical values  
2. **Feature Engineering** â€” domain-based variable creation and transformation  
3. **Model Training & Optimization** â€” testing classical and gradient boosting models  
4. **Explainability** â€” interpreting predictions via SHAP & PDP  

---

### ğŸ¯ **Goal**

To model and understand which patient and hospital factors drive  
**longer inpatient durations**, improving **resource allocation** and **clinical decision-making**.

---

```bash
Diabetes_Hospital_Stay_Prediction/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # Original UCI dataset (diabetic_data.csv)
â”‚ â””â”€â”€ processed/ # Cleaned dataset after preprocessing
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ 01_data_exploration.ipynb # EDA & initial data understanding
â”‚ â”œâ”€â”€ 02_feature_engineering.ipynb # Feature creation, encoding, scaling
â”‚ â”œâ”€â”€ 03_model_training.ipynb # Training, tuning & evaluation
â”‚ â””â”€â”€ 04_model_explainability.ipynb # Feature importance, PDP, ICE
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ init.py # Module initialization
â”‚ â”œâ”€â”€ preprocessing.py # Cleaning, transformation, outlier handling
â”‚ â”œâ”€â”€ feature_engineering.py # Custom feature generation & encoding
â”‚ â”œâ”€â”€ training.py # Model definitions and evaluation functions
â”‚ â””â”€â”€ explainability.py # Visualization and interpretation utilities
â”‚
â”œâ”€â”€ models/
â”‚ â””â”€â”€ final_lgbm_model.pkl # Saved best model (LightGBM)
â”‚
â”œâ”€â”€ assets/
â”‚ â”œâ”€â”€ images/ # Figures, diagrams & plots for README
â”‚ â””â”€â”€ results/ # Evaluation visuals (feature importances, curves)
â”‚
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ .gitignore # Ignored files & directories
â”œâ”€â”€ LICENSE # License information (MIT recommended)
â””â”€â”€ README.md # Project documentation

```
---

### ğŸ§© **Folder Highlights**

- **`data/`** â†’ Raw and processed dataset files  
- **`notebooks/`** â†’ Step-by-step Jupyter notebooks used for analysis  
- **`src/`** â†’ Core Python scripts for reproducibility and modularity  
- **`models/`** â†’ Trained model artifacts (.pkl)  
- **`assets/`** â†’ Visuals for reporting and presentation  

---

### ğŸ’¡ **Note**
Each notebook can be executed independently, but they are **sequentially structured**:
`01_data_exploration â†’ 02_feature_engineering â†’ 03_model_training â†’ 04_model_explainability`.

---

---

## ğŸ§  Methodology & Models

This project follows a structured **machine learning workflow** focused on predictive modeling for healthcare analytics.  
The pipeline combines **data-driven feature extraction**, **regression-based modeling**, and **model explainability**.

### ğŸ”¹ Step-by-Step Methodology

| Stage | Description |
|-------|--------------|
| **1ï¸âƒ£ Data Understanding (EDA)** | Inspection of demographics, lab results, diagnoses, and hospitalization trends. |
| **2ï¸âƒ£ Feature Engineering** | Derived variables such as `meds_per_day`, `labs_per_day`, and `prior_visits` were created to represent patient complexity. |
| **3ï¸âƒ£ Outlier & Encoding Strategy** | Winsorization at [1%, 99%] for extreme values; categorical variables encoded via one-hot encoding. |
| **4ï¸âƒ£ Model Training & Evaluation** | Compared linear and ensemble regressors using 5-fold cross-validation. |
| **5ï¸âƒ£ Model Explainability** | Used feature importance, PDP, and ICE plots to interpret the model. |

---

### âš™ï¸ **Trained Models**

| Model | Category | Purpose |
|--------|-----------|----------|
| **Linear Regression** | Baseline | Simple interpretability baseline |
| **Ridge / Lasso** | Regularized | Controls overfitting through penalization |
| **Random Forest Regressor** | Ensemble | Non-linear benchmark with feature averaging |
| **XGBoost Regressor** | Gradient Boosting | Efficient boosting-based performance |
| **LightGBM Regressor** | Gradient Boosting | Final model with best overall generalization |

---

### ğŸ§© **Evaluation Metrics**

- **RÂ² (Coefficient of Determination)** â€” overall model fit  
- **RMSE (Root Mean Squared Error)** â€” penalizes large errors  
- **MAE (Mean Absolute Error)** â€” average prediction deviation  
- **5-Fold Cross Validation** â€” ensures stability across samples  

---

### ğŸ”§ **Hyperparameter Tuning**

- **Random Forest** â†’ `GridSearchCV` for optimal depth & features  
- **XGBoost & LightGBM** â†’ `RandomizedSearchCV` for learning rate, depth, and regularization parameters  
- **Best model:** **LightGBM (RÂ² â‰ˆ 0.9996, RMSE â‰ˆ 0.0577)**  

---

---

## ğŸ“Š Results & Explainability

The following table summarizes the **cross-validation and test results** for all models tested in this project:

| Model | RÂ² | RMSE | MAE |
|:------|:---:|:----:|:----:|
| **Random Forest** | 0.9997 | 0.0530 | 0.0050 |
| **LightGBM** | 0.9990 | 0.0954 | 0.0577 |
| **XGBoost** | 0.9990 | 0.0961 | 0.0511 |
| **CatBoost** | 0.9986 | 0.1129 | 0.0716 |
| **Lasso** | 0.7081 | 1.6174 | 1.2038 |
| **Ridge** | 0.7080 | 1.6175 | 1.2032 |
| **AdaBoost** | 0.6893 | 1.6661 | 1.5295 |
| **Linear Regression** | -6365.96 | 116.97 | 2.1856 |

---

### ğŸ† **Final Model: LightGBM**

After extensive evaluation and hyperparameter optimization,  
**LightGBM** was selected as the **final production model** due to its superior balance of accuracy, efficiency, and interpretability.

- **Best Cross-Validation RÂ²:** 0.9996  
- **Test RMSE:** 0.0577  
- **Test MAE:** 0.0108  
- **Final Model Saved:** `models/final_lgbm_model.pkl`

---

### ğŸ” **Model Explainability**

**Feature Importance (Top Predictors):**
- `num_medications`  
- `num_lab_procedures`  
- `number_diagnoses`  
- `discharge_disposition_id`  
- `number_inpatient`

**Visual Interpretations:**
- **Partial Dependence (PDP)** â€” shows average impact of key features  
- **Individual Conditional Expectation (ICE)** â€” reveals local variability  
- **Combined PDP + ICE** â€” used for deeper insight into feature behavior  

<p align="center">
  <img src="assets/results/feature_importance.png" width="550" alt="Feature Importance"/>
</p>

<p align="center">
  <img src="assets/results/pdp_ice_combined.png" width="550" alt="PDP + ICE"/>
</p>

---

### ğŸ’¾ **Reproducibility**

All experiments are reproducible using the notebooks provided:  
`01_data_exploration â†’ 02_feature_engineering â†’ 03_model_training â†’ 04_model_explainability`.

---

---

## ğŸ’» How to Run Locally

You can reproduce the full pipeline locally or in a Colab environment.

### ** Clone the Repository**
```bash
git clone https://github.com/ahmetyasirduman/Diabetes_Hospital_Stay_Prediction.git
cd Diabetes_Hospital_Stay_Prediction
```

### ğŸ“‚ Clone the Repository

To get started, clone this repository and navigate into the project directory:

```bash
git clone https://github.com/ahmetyasirduman/Diabetes_Hospital_Stay_Prediction.git
cd Diabetes_Hospital_Stay_Prediction
```

### ğŸ§  Run the Notebooks

The notebooks are organized sequentially, each representing a distinct stage of the data analysis pipeline:

| Notebook | Purpose |
|-----------|----------|
| **01_data_exploration.ipynb** | Exploratory Data Analysis (EDA): data cleaning, missing values, correlation, and hypothesis testing |
| **02_feature_engineering.ipynb** | Feature creation, outlier handling, encoding, and dataset preparation |
| **03_model_training.ipynb** | Model training, hyperparameter tuning (Grid & Random Search), and evaluation metrics |
| **04_model_explainability.ipynb** | Feature importance analysis, Partial Dependence (PDP), and ICE visualization |

> ğŸ’¡ *To reproduce the workflow, run the notebooks in the above order.  
Each notebook can also be executed independently for modular experimentation.*

---

### ğŸ’¾ Load the Final Model

After training, the best-performing model (**LightGBM**) is automatically saved in the `models/` directory.  
You can easily load and use it for prediction as shown below:

```python
import joblib

# Load the final model
model = joblib.load("models/final_lgbm_model.pkl")

# Example: make predictions
predictions = model.predict(X_test)
```

## ğŸ“š References & Citation

This project uses the publicly available **UCI Machine Learning Repository** dataset:

> **Dataset:** Diabetes 130-US Hospitals for Years 1999â€“2008  
> **Source:** [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/diabetes+130-us+hospitals+for+years+1999-2008)  
> **Authors:** Strack et al., *Journal of Biomedical Informatics, 2014.*

**Reference:**  
> Strack B. et al., *Impact of HbA1c measurement on hospital readmission rates: analysis of 70,000 clinical database cases.*  
> *Journal of Biomedical Informatics, 2014, Volume 53, Pages 240â€“250.*

---

### âœï¸ Citation

If you use this repository or adapt its methods, please cite it as:

```bibtex
@misc{duman2025diabetesstay,
  author       = {Ahmet Yasir Duman},
  title        = {Diabetes Hospital Stay Prediction: Regression-based Clinical Length-of-Stay Modeling},
  year         = {2025},
  url          = {https://github.com/ahmetduman23/Diabetes_Hospital_Stay_Prediction}
}

### âš–ï¸ License

This project is released under the **MIT License** â€” you are free to use, modify, and distribute the code  
for educational, research, or non-commercial purposes, provided that proper attribution is given.

> Â© 2025 Ahmet Yasir Duman â€” All rights reserved.
